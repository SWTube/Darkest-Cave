{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inceptionV3(dynamic-shape).ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"rlrjxhoZXqjQ"},"source":["import tensorflow as tf\n","print(tf.__version__)\n","\n","import IPython.display as display\n","\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","mpl.rcParams['figure.figsize'] = (12,12)\n","mpl.rcParams['axes.grid'] = False\n","\n","import numpy as np\n","import time\n","import functools"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImxbKfuV0CaL"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3jIHjdocz0n"},"source":["# for file path\n","import natsort\n","import platform\n","import glob\n","import os\n","\n","import cv2 as cv\n","from google.colab.patches import cv2_imshow # cv2_imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAQNw4teYecH"},"source":["content_path = tf.keras.utils.get_file('belfry.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/belfry-2611573_1280.jpg')\n","style_path = tf.keras.utils.get_file('style23.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg')\n","\n","style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')\n","style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U36f73iqMrVO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuuAzQx6Ygdz"},"source":["# Function to load an image from a file, and add a batch dimension.\n","def load_img(path_to_img):\n","  img = tf.io.read_file(path_to_img)\n","  img = tf.io.decode_image(img, channels=3)\n","  img = tf.image.convert_image_dtype(img, tf.float32)\n","  img = img[tf.newaxis, :]\n","\n","  return img\n","\n","# Function to pre-process by resizing an central cropping it.\n","def preprocess_image(image, target_dim):\n","  # Resize the image so that the shorter dimension becomes 256px.\n","  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)\n","  short_dim = min(shape)\n","  scale = target_dim / short_dim\n","  new_shape = tf.cast(shape * scale, tf.int32)\n","  image = tf.image.resize(image, new_shape)\n","\n","  # Central crop the image.\n","  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)\n","\n","  return image\n","\n","# Load the input images.\n","content_image = load_img(content_path)\n","style_image = load_img(style_path)\n","\n","# Preprocess the input images.\n","preprocessed_content_image = preprocess_image(content_image, 384)\n","preprocessed_style_image = preprocess_image(style_image, 256)\n","\n","print('Style Image Shape:', preprocessed_style_image.shape)\n","print('Content Image Shape:', preprocessed_content_image.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRTTQ7wLYiKQ"},"source":["def imshow(image, title=None):\n","  if len(image.shape) > 3:\n","    image = tf.squeeze(image, axis=0)\n","\n","  plt.imshow(image)\n","  if title:\n","    plt.title(title)\n","\n","plt.subplot(1, 2, 1)\n","imshow(preprocessed_content_image, 'Content Image')\n","\n","plt.subplot(1, 2, 2)\n","imshow(preprocessed_style_image, 'Style Image')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWJN85_IYj0Z"},"source":["# Function to run style prediction on preprocessed style image.\n","def run_style_predict(preprocessed_style_image):\n","  # Load the model.\n","  interpreter = tf.lite.Interpreter(model_path=style_predict_path)\n","\n","  # Set model input.\n","  interpreter.allocate_tensors()\n","  input_details = interpreter.get_input_details()\n","  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_style_image)\n","\n","  # Calculate style bottleneck.\n","  interpreter.invoke()\n","  style_bottleneck = interpreter.tensor(\n","      interpreter.get_output_details()[0][\"index\"]\n","      )()\n","\n","  return style_bottleneck\n","\n","# Calculate style bottleneck for the preprocessed style image.\n","style_bottleneck = run_style_predict(preprocessed_style_image)\n","print('Style Bottleneck Shape:', style_bottleneck.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnsgpiPkYlKU"},"source":["# Run style transform on preprocessed style image\n","def run_style_transform(style_bottleneck, preprocessed_content_image):\n","  # Load the model.\n","  interpreter = tf.lite.Interpreter(model_path=style_transform_path)\n","\n","  # Set model input.\n","  input_details = interpreter.get_input_details()\n","  interpreter.allocate_tensors()\n","\n","  # Set model inputs.\n","  interpreter.set_tensor(input_details[0][\"index\"], preprocessed_content_image)\n","  interpreter.set_tensor(input_details[1][\"index\"], style_bottleneck)\n","  interpreter.invoke()\n","\n","  # Transform content image.\n","  stylized_image = interpreter.tensor(\n","      interpreter.get_output_details()[0][\"index\"]\n","      )()\n","\n","  return stylized_image\n","\n","# Stylize the content image using the style bottleneck.\n","stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)\n","\n","# Visualize the output.\n","imshow(stylized_image, 'Stylized Image')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cTy0C6-Ym8Q"},"source":["# Calculate style bottleneck of the content image.\n","style_bottleneck_content = run_style_predict(\n","    preprocess_image(content_image, 256)\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rKxoEOSYoi7"},"source":["# Define content blending ratio between [0..1].\n","# 0.0: 0% style extracts from content image.\n","# 1.0: 100% style extracted from content image.\n","content_blending_ratio = 0.01 #@param {type:\"slider\", min:0, max:1, step:0.01}\n","\n","# Blend the style bottleneck of style image and content image\n","style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \\\n","                           + (1 - content_blending_ratio) * style_bottleneck\n","\n","# Stylize the content image using the style bottleneck.\n","stylized_image_blended = run_style_transform(style_bottleneck_blended,\n","                                             preprocessed_content_image)\n","\n","# Visualize the output.\n","imshow(stylized_image_blended, 'Blended Stylized Image')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_7jKCOXcoOG"},"source":["content_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Content_Images/skeleton_128/sprite_00.png\"\n","style_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Style_Images/horror/horror27.jpg\"\n","\n","# 원본 파일의 크기를 알 수 있게 하는 코드\n","origin_image = cv.imread(content_location, cv.IMREAD_UNCHANGED)\n","origin_image_shape = origin_image.shape\n","\n","# Load the input images.\n","content_image = load_img(content_location)\n","style_image = load_img(style_location)\n","\n","# Preprocess the input images.\n","preprocessed_content_image = preprocess_image(content_image, 384)\n","preprocessed_style_image = preprocess_image(style_image, 256)\n","\n","# Calculate style bottleneck for the preprocessed style image.\n","style_bottleneck = run_style_predict(preprocessed_style_image)\n","\n","img_transformed = run_style_transform(style_bottleneck, preprocessed_content_image)\n","\n","# model이 반환한 이미지와 사이즈 동일하게 origin image 변환(자동화 완료)\n","shape = preprocessed_content_image.shape[1]\n","x, y = shape, shape\n","origin_image_resized = cv.resize(origin_image, dsize=(y,x))\n","\n","# alpha channel 추가\n","final = cv.cvtColor(img_transformed[0], cv.COLOR_RGB2RGBA)\n","\n","final[:, :, 3] = origin_image_resized[:,:,3]\n","\n","# final image 사이즈를 original image 사이즈로 변환\n","x, y = origin_image_shape[0], origin_image_shape[1]\n","final = cv.resize(final, dsize=(y,x))\n","\n","# Visualize the output.\n","imshow(final, 'Blended Stylized Image')\n","\n","# float to int 클리핑 (약간의 이미지 깨짐 현상 있음)\n","final = (final * 255).astype(np.uint)\n","\n","# plt 기준의 bgr을 cv 기준의 rgb로 변경\n","b, g, r, a = cv.split(final)\n","final = cv.merge([r,g,b,a])\n","\n","cv2_imshow(final)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZMLRoPeklkw"},"source":["# 경로 설정 명세서\n","platform_path = platform.platform()\n","\n","IsColab = \"bionic\" in platform_path\n","if IsColab:\n","  style_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Style_Images/*\"\n","  content_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Content_Images/*\"\n","  styled_location = \"/content/drive/Shareddrives/SWTube/프로젝트/044. 2021 소융튜브 특성화 프로젝트/데이터 팀/mount_drive/Darkest-Cave/Data/Styled_Images/\"\n","else:\n","  style_location = 'Style_Images/*'\n","  content_location = \"Content_Images/*\"\n","  styled_location = \"Styled_Images/\"\n","\n","# 해당 폴더 내에 존재하는 모든 폴더 리스트 불러오기\n","style_folder_list = glob.glob(style_location)\n","style_images_list = glob.glob(style_folder_list[0] + \"/*\")\n","\n","# Style_location\n","# Style_Images/TEXTURE/*.jpg or png\n","\n","# style_images_list, style_image 활용\n","# style_image = style_images_list[index]\n","\n","# Content_location\n","  # Content_Images/ASSET_NAME/*.png\n","content_folder_list = glob.glob(content_location) # Content_Images/ASSET_NAME\n","\n","# content_images_list, content_image 활용\n","# content_images_list = glob.glob(content_folder_list[index] + \"/*\")\n","# content_image = style_images_list[index]\n","\n","# Styled_location\n","  # Styled_Images/ASSET_NAME/*.png\n","# asset_name = os.path.split(content_folder_list[index])\n","\n","# 폴더 생성\n","def createFolder(directory):\n","    try:\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","    except OSError:\n","        print ('Error: Creating directory. ' +  directory)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kMn5aioVolM_"},"source":["# 구글 코랩에서 장시간 사용하기\n","## F12 개발자 모드 후 Console에 입력\n","\n","\n","\n","}\n","\n","```javascript\n","function ClickConnect() {\n","    var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); \n","    buttons.forEach(function(btn) { \n","        btn.click(); \n","    }); \n","    console.log(\"1분마다 자동 재연결\"); \n","    document.querySelector(\"colab-toolbar-button#connect\").click(); \n","} \n","setInterval(ClickConnect,1000*60);\n","```\n","\n","\n","```javascript\n","function CleanCurrentOutput(){ \n","    var btn = document.querySelector(\".output-icon.clear_outputs_enabled.output-icon-selected[title$='현재 실행 중...'] iron-icon[command=clear-focused-or-selected-outputs]\"); \n","    if(btn) { console.log(\"30분마다 출력 지우기\");\n","     btn.click(); \n","    } \n","} \n","setInterval(CleanCurrentOutput,1000*60*30);\n","```"]},{"cell_type":"code","metadata":{"id":"ssdBPRCNksSp"},"source":["## main code\n","import time\n","start = time.time()\n","\n","# ★사용 모델명★\n","model_name = \"inceptionV3(dynamic-shape)\"\n","\n","# 스타일 폴더 리스트\n","for SF_index, SF_value in enumerate(style_folder_list):\n","  style_images_list = glob.glob(style_folder_list[SF_index] + \"/*\")\n","  style_folder_name = os.path.split(style_folder_list[SF_index]) # horror, ice, dark .etc\n","\n","  style_images_list = natsort.natsorted(style_images_list)\n","\n","  # 스타일 이미지 리스트\n","  for SI_index, SI_value in enumerate(style_images_list):\n","    style_image_name = os.path.split(style_images_list[SI_index]) # horror1, horror2, horror3, .etc\n","    \n","    # 스타일 이미지 선택\n","    print(SI_value)\n","    style_image = load_img(SI_value)\n","    preprocessed_style_image = preprocess_image(style_image, 256)\n","\n","    # 콘텐트 폴더 리스트\n","    for CF_index, CF_value in enumerate(content_folder_list):\n","\n","      #콘텐트 이미지 리스트\n","      content_images_list = glob.glob(content_folder_list[CF_index] + \"/*\")\n","      content_images_list = natsort.natsorted(content_images_list)\n","\n","      # 스타일 전이\n","      for CI_index, CI_value in enumerate(content_images_list):\n","\n","        # 저장 경로 생성\n","        asset_folder = os.path.split(content_folder_list[CF_index]) # gobline, zombie, male .etc\n","        asset_name = os.path.split(CI_value)\n","\n","        save_folder_model = styled_location + model_name\n","        save_folder_style = save_folder_model + \"/\" + style_folder_name[1]\n","        save_folder_style_index = save_folder_style + \"/\" + style_image_name[1]\n","        save_folder_style_index_content = save_folder_style_index + \"/\" + asset_folder[1]\n","        \n","        createFolder(save_folder_style) # VGG19, AdaIN, efficientNet\n","        createFolder(save_folder_style) # horror, ice, dark\n","        createFolder(save_folder_style_index) # horror1, horror2, horror3\n","        createFolder(save_folder_style_index_content) # goblin, zombie, male\n","\n","        save_path = save_folder_style_index_content + \"/\"\n","        save_path = save_path + asset_name[1] + f'_{CI_index}_final.png'\n","\n","        # 이미 있는 파일이면 건너뛰기\n","        if os.path.exists(save_path):\n","          continue\n","        else:\n","          try:\n","            # 원본 파일의 크기를 알 수 있게 하는 코드\n","            origin_image = cv.imread(CI_value, cv.IMREAD_UNCHANGED)\n","            origin_image_shape = origin_image.shape\n","\n","            # Load the input images.\n","            content_image = load_img(CI_value)\n","\n","            # Preprocess the input images.\n","            preprocessed_content_image = preprocess_image(content_image, 384)\n","          \n","            # Calculate style bottleneck for the preprocessed style image.\n","            style_bottleneck = run_style_predict(preprocessed_style_image)\n","            img_transformed = run_style_transform(style_bottleneck, preprocessed_content_image)\n","\n","            # model이 반환한 이미지와 사이즈 동일하게 origin image 변환(자동화 완료)\n","            shape = preprocessed_content_image.shape[1]\n","            x, y = shape, shape\n","            origin_image_resized = cv.resize(origin_image, dsize=(y,x))\n","\n","            # alpha channel 추가\n","            final = cv.cvtColor(img_transformed[0], cv.COLOR_RGB2RGBA)\n","            final[:, :, 3] = origin_image_resized[:,:,3]\n","\n","            # final image 사이즈를 original image 사이즈로 변환\n","            x, y = origin_image_shape[0], origin_image_shape[1]\n","            final = cv.resize(final, dsize=(y,x))\n","\n","            # float to int 클리핑 (약간의 이미지 깨짐 현상 있음)\n","            final = (final * 255).astype(np.uint)\n","\n","            # plt 기준의 bgr을 cv 기준의 rgb로 변경\n","            b, g, r, a = cv.split(final)\n","            final = cv.merge([r,g,b,a])\n","          \n","            # 저장\n","            cv.imwrite(save_path, final)\n","          except:\n","            print(CI_value)\n","            pass\n","\n","end = time.time()\n","print(\"전체 소요 시간: {:.1f}\".format(end-start))"],"execution_count":null,"outputs":[]}]}